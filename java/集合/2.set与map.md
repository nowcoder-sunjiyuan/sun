# Java 核心集合：Set 与 Map 深度解析

## 目录
1. [HashMap vs. TreeMap：核心区别](#hashmap-vs-treemap-核心区别)
2. [深入 TreeMap：红黑树的威力](#深入-treemap红黑树的威力)
    - [什么是红黑树？](#什么是红黑树)
    - [TreeMap 的核心特性](#treemap的核心特性)
3. [HashMap 核心机制：扩容与树化](#hashmap-核心机制扩容与树化)
    - [主线任务：扩容 (Resize)](#主线任务扩容-resize)
    - [支线任务：树化 (Treeify)](#支线任务树化-treeify)
4. [ConcurrentHashMap 的并发控制演进](#concurrenthashmap-的并发控制演进)
    - [Java 7：分段锁 (Segment Locking)](#java-7分段锁-segment-locking)
    - [Java 8：CAS + synchronized 锁头节点](#java-8cas--synchronized-锁头节点)

---

## HashMap vs. TreeMap：核心区别

| 特性             | HashMap                                  | TreeMap                                                  |
| ---------------- | ---------------------------------------- | -------------------------------------------------------- |
| **底层结构**     | 哈希表 (数组 + 链表/红黑树)              | 红黑树 (Red-Black Tree)                                  |
| **排序性**       | **无序**。元素的存储和迭代顺序不保证一致。 | **有序**。默认按 Key 的自然顺序排序，或通过 `Comparator` 自定义排序。 |
| **增删改查性能** | 平均 **O(1)**                            | **O(log n)**                                             |
| **Key 要求**     | Key 需要正确实现 `hashCode()` 和 `equals()`。 | Key 必须实现 `Comparable` 接口，或在构造时传入 `Comparator`。 |
| **null Key**     | 允许 1 个 `null` key。                   | **不允许** `null` key (除非 `Comparator` 特殊处理)。       |
| **主要应用场景** | 追求极致的插入和查找性能，对顺序无要求。 | 需要按 Key 排序，或进行范围查找、顺序遍历的场景。          |

---

## 深入 TreeMap：红黑树的威力

`TreeMap` 的所有特性都源于其底层的数据结构——**红黑树**。

### 什么是红黑树？

你可以将红黑树理解为一种**“自平衡的二叉查找树”**。

-   **二叉查找树 (BST)**：一个基础规则是“左子节点 < 父节点 < 右子节点”。这使得查找非常高效。但如果插入的数据是顺序的（例如 1, 2, 3, 4, 5），BST 就会退化成一个链表，查找效率从 `O(log n)` 急剧下降到 `O(n)`。

-   **自平衡**：红黑树通过一套精妙的规则（节点着色、旋转、变色）来确保树在插入和删除后，**始终保持大致的平衡**。它确保从根节点到最远叶子节点的路径长度，不会超过到最近叶子节点路径长度的两倍。

这个“自平衡”机制，是 `TreeMap` 能够稳定地提供 `O(log n)` 时间复杂度的关键保障。

![红黑树示意图](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Red-black_tree_example.svg/400px-Red-black_tree_example.svg.png)

### TreeMap 的核心特性

1.  **有序性 (Ordering)**
    这是 `TreeMap` 最核心的价值。由于红黑树的结构，`TreeMap` 中的所有键都是有序的。当你遍历 `TreeMap` 时，得到的元素顺序是确定且排好序的，这对于需要按顺序处理数据的场景至关重要。

2.  **强大的导航方法 (NavigableMap)**
    `TreeMap` 实现了 `NavigableMap` 接口，提供了一系列非常实用的方法来利用其有序性进行“导航”和范围查询：

    -   `firstKey()` / `lastKey()`: 获取第一个（最小）或最后一个（最大）的 Key。
    -   `ceilingKey(K key)`: 找到 **大于等于** 给定 `key` 的最小 Key。
    -   `floorKey(K key)`: 找到 **小于等于** 给定 `key` 的最大 Key。
    -   `higherKey(K key)`: 找到 **严格大于** 给定 `key` 的最小 Key。
    -   `lowerKey(K key)`: 找到 **严格小于** 给定 `key` 的最大 Key。
    -   `subMap(K fromKey, K toKey)`: 截取 Map 的一部分，形成一个左闭右开的子 Map 视图。
    -   `descendingMap()`: 返回一个与原 Map 顺序相反的逆序视图。

    这些方法让 `TreeMap` 在处理诸如“查找价格不高于 50 元的最近商品”、“查找指定时间点之后的第一条日志”等场景时，显得极为高效和方便。

---

## HashMap 核心机制：扩容与树化

为了深刻理解 `HashMap` 的性能，必须掌握其内部的两个核心动态调整机制：**扩容**和**树化**。这两者协同工作，确保 `HashMap` 在各种情况下都能维持高效。

### 主线任务：扩容 (Resize)

扩容是 `HashMap` 保证其 `O(1)` 平均时间复杂度的**首要且最基本**的手段。它的目标是确保哈希桶（数组）足够分散，避免元素过度拥挤。

**触发条件：**
当 `HashMap` 中存储的元素数量 `size` 超过了“容量 `capacity` × 加载因子 `loadFactor`”时，就会触发扩容。
-   `capacity`: 当前数组的长度（默认为 16）。
-   `loadFactor`: 加载因子（默认为 0.75）。
-   **阈值 (Threshold)**: `capacity * loadFactor`。例如，容量为 16 时，阈值为 12。当存入第 13 个元素时，就会触发扩容。

**扩容过程：**
1.  创建一个新的数组，其容量是旧数组的**两倍**（例如，从 16 变为 32）。
2.  遍历旧数组中的每一个元素（包括链表和红黑树中的所有节点）。
3.  对每一个元素**重新计算**其在新数组中的位置（rehash）。
4.  将元素放入新数组的对应位置。
5.  这个过程完成后，旧数组被废弃。

**核心思想：** 扩容是解决哈希冲突的**常规手段**。通过增加桶的数量，让元素分布得更稀疏，从而保持链表的简短，确保查询效率。

### 支线任务：树化 (Treeify)

树化是一种**应对极端情况的补救措施**。它专门处理“即使容量足够大，但依然有大量元素集中在同一个桶中”的场景，这通常是由糟糕的 `hashCode()` 实现导致的。

**双重触发条件：**
树化必须**同时满足**以下两个条件：

1.  **链表长度阈值**：某个桶中的链表长度达到了 **8**。
2.  **最小容量阈值**：`HashMap` 的整体数组容量 `capacity` 已经达到了 **64**。

**决策逻辑：**
当一个桶的链表长度达到 8 时，`HashMap` 会进行一次检查：
-   **如果当前容量 `< 64`**：`HashMap` 会认为，冲突的原因更可能是“桶不够多，地方太挤”，而不是 `hashCode()` 的问题。因此，它会**选择优先进行扩容 (Resize)**，而不是树化。扩容后，这个长链表上的元素很可能会被重新散列到不同的桶中，问题就解决了。
-   **如果当前容量 `>= 64`**：`HashMap` 则认为，在有至少 64 个桶可选的情况下，依然有 8 个元素挤在同一个桶里，这极有可能是 `hashCode()` 设计不佳导致的“顽固”冲突。此时再扩容也无济于事，因此会**执行树化**，将该桶的链表结构转换为红黑树，将该位置的查询时间复杂度从 `O(n)` 优化到 `O(log n)`。

**总结：**
-   **扩容是 `HashMap` 的“进攻”策略**，主动通过扩大空间来维持高性能。
-   **树化是 `HashMap` 的“防守”策略**，被动地应对最坏情况，确保即使在哈希分布极不均匀时，性能也不会 catastrophic 下降。

---

## ConcurrentHashMap 的并发控制演进

`ConcurrentHashMap` 是 `java.util.concurrent` 包下的明星类，它的核心目标是在保证线程安全的同时，提供极高的并发性能。为了实现这一目标，它的锁机制经历了从“粗”到“细”的演进。

### Java 7：分段锁 (Segment Locking)

在 Java 7 及以前，`ConcurrentHashMap` 内部由一个 `Segment` 数组和一个 `HashEntry` 数组组成。

-   **`Segment`**：可以理解为一个“小的 `Hashtable`”。它本身继承自 `ReentrantLock`，所以每个 `Segment` 对象自己就是一把锁。
-   **结构**：`ConcurrentHashMap` 包含一个 `Segment[]` 数组。当一个操作需要写入数据时，它会先根据 key 的哈希值定位到具体的 `Segment`，然后**只对这个 `Segment` 加锁**。

**工作方式：**
-   默认情况下，`ConcurrentHashMap` 会创建 16 个 `Segment`。这意味着，在理想情况下，最多可以有 **16 个线程同时**对这个 Map进行写操作，只要它们操作的 key 被路由到了不同的 `Segment` 上。
-   `get` 操作大多数时候**不需要加锁**，因为它利用了 `volatile` 关键字来保证内存可见性。

**优点**：相比于对整个 Map 加一把锁的 `Hashtable`，并发性能大大提升。
**缺点**：并发度受限于 `Segment` 的数量，且 `Segment` 一旦创建，数量就无法改变，不够灵活。如果数据分布不均，某个 `Segment` 依然可能成为性能瓶颈。

### Java 8：CAS + synchronized 锁头节点

从 Java 8 开始，`ConcurrentHashMap` 的设计发生了根本性的变化。它放弃了 `Segment` 的设计，回归到与 `HashMap` 类似的“数组 + 链表 / 红黑树”的结构，但通过更精细的手段实现了更高的并发性。

你的猜测“在数组每个 node 上加锁”非常接近了，精确地说是：对每个桶（bucket）的“头节点”进行加锁。

这里的**桶（Bucket）**，指的就是 `ConcurrentHashMap` 底层数组中的每一个“格子”或“槽位”。**头节点（Head Node）** 则是存放在该槽位里的第一个元素。

```
       <<  底层的数组 (table) >>
       +---+---+---+---+---+---+---
index: | 0 | 1 | 2 | 3 | 4 | 5 | ...
       +---+---+---+---+---+---+---
         |   |   |   |   |   |
         |   |   |   |   |   +--> null (这个桶是空的)
         |   |   |   |   |
         |   |   |   |   +------> NodeX (这个桶只有一个元素，NodeX是头节点)
         |   |   |   |
         |   |   |   +----------> null (这个桶是空的)
         |   |   |
         |   |   +--------------> NodeA -> NodeB -> NodeC (这个桶是链表，NodeA是头节点)
         |   |
         |   +------------------> null (这个桶是空的)
         |
         +----------------------> TreeNodeP (root) (这个桶是红黑树，TreeNodeP是头节点)
                                     /   \
                                  ...     ...
```

**工作方式：**
1.  **初始化桶 (CAS)**：当一个线程尝试向一个空的桶中（如上图 `index 3`）放入第一个元素时，它**不加锁**，而是使用**无锁的 CAS (Compare-And-Swap)** 操作来完成。如果成功，则完全避免了锁的开销。如果失败（说明有其他线程抢先了），则进入下一步。

2.  **锁定头节点 (`synchronized`)**：当线程需要操作一个**已经有元素**的桶时（如 `index 2`），它会使用 `synchronized` 关键字**锁定该桶的头节点**（即 `NodeA`）。
    -   一旦锁定了 `NodeA`，该线程就可以安全地遍历这个桶的链表或红黑树，并执行插入、更新或删除操作。
    -   在此期间，其他线程如果也想操作**同一个桶**（`index 2`），就会在 `synchronized(NodeA)` 处被阻塞。
    -   但是，如果其他线程操作的是**不同的桶**（例如 `index 0`），它们就可以完全并行执行，因为它们锁定的是各自桶的头节点（`TreeNodeP`），互不影响。

**优点：**
-   **极细的锁粒度**：锁的粒度从 `Segment` 级别缩小到了“数组的每个桶”级别，并发度从固定的 16 提升到了数组的容量大小（例如 64、128...）。
-   **无锁优化**：在无竞争的情况下（向空桶放数据），完全是无锁操作，性能极高。
-   **`synchronized` 优化**：Java 8 对 `synchronized` 锁进行了大量优化（如锁膨胀），其性能在很多场景下已经不输于 `ReentrantLock`。

这个“CAS + 锁头节点”的设计，是现代 `ConcurrentHashMap` 高并发性能的关键所在。
