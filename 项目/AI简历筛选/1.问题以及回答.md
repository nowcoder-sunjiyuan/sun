模型效果方面
1. 你们怎么给用户保证这个准确率？他们怎么觉得你的效果好？？
2. 你既然说简历那么多，那hr直接在平台上搜索是不是效果就足够好了？？


模型实现方面
1. 为啥要沟通实现这个过程，直接让用户填表不更好吗？
2. 拆维度，你们是怎么想到拆维度的？？一把梭的方案跟他比差在哪，这个变化过程是怎样的？
3. 你能举例子说一下，不同的职位有哪些维度吗？？
4. 维度，你说足够细致，问题来了，模型提取的维度你怎么知道他一定是合理的？？比如用户写了redis，kafka，mysql这样的，难道redis，kafka，mysql这都算三个维度？？
5. 你们为什么在建模的时候选择Claude？评估的时候选择豆包？那claude把你们封了，你们是不是就建不了模了？？
6. 你说到kimi-k2出来的时候，你们换了发现效果不好，效果不好在哪？？你能举例子吗？
7. 你们做的任何改动，怎么评估他效果会更好？难道只是跑100份案例？？万一只是针对这个客户效果好，下个客户效果差呢？？
8. 你们判断筛选规则是正确的？？这一步的东西也是大模型输出的吗？
9. 我感觉你们这个有点空，就比如说，现在跟客户的一致率不一致。究竟是维度的问题，还是筛选规则的问题呢？？？怎么判断


模型稳定性
1. 你们怎么评估每个阶段的效果？
2. 换模型后你们怎么评估每一段的效果？
3. 模型中间某一步幻觉了，是不是会造成后面的巨大的问题，怎么办呢？

最终
1. 你觉得你这个目前存在的最大问题是什么，需要改进的地方有哪些？
2. 你这个东西看起来好像不复杂
---

# AI 简历评估项目面试问答

## 模型效果方面

### 1. 你们怎么给用户保证这个准确率？他们怎么觉得你的效果好？？

我们通过一个“三步走”的策略来向用户证明并保证效果，核心是“眼见为实”和“持续对齐”。

1.  **第一步：基于历史数据的冷启动验证。** 在正式使用前，我们会邀请客户提供一批他们人工筛选过的简历（例如 100-200 份），并附上他们的筛选结果（通过/淘汰/待定）。我们会用我们的 Agent 对这批简历进行建模与分析。随后客户正式使用之前，再提供一批简历100份。用agent进行分析和筛选，对每一份简历输出一份详细的**评估报告**。并且最终通过与否这些案例会生成**对齐报告**这份报告会清晰地展示 AI 的判断结果和客户历史判断结果的一致率（我们称之为“对齐率”）。通过这种方式，客户可以得到一个非常直观且量化的初步评估，例如“AI 的筛选结果与您过去 95% 的判断一致，不一致的情况下，看是谁的问题，看是否能够进一步调优，或者说问题可忽略”。

2.  **第二步：提供可解释、可追溯的筛选报告。** 我们不只给出一个“通过”或“不通过”的冷冰冰结果。每一份简历，系统都会生成一份详细的分析报告。报告会清晰地列出，在每一个关键维度上（例如“商业化经验”、“并发处理能力”），AI 是如何给这份简历打分的（分了哪一档），以及最终的筛选决策是如何基于这些维度的评分和预设规则得出的。当 HR 看到 AI 拒绝一份简历的理由和他自己想的一模一样时，信任感就建立起来了。而且我们有筛选理由的生成，<mark>帮助客户认知到这个候选人其实很有潜力或者别的有点是他需要的</mark>

3.  **第三步：建立持续反馈与优化的闭环。** 我们的系统内置了反馈机制。在实际使用中，如果 HR 对 AI 的某个判断不满意，可以使用中，做出改动，比如标记这个简历是不通过的。<mark>然后会给出一个反馈框，为什么不通过：比如说这个人只是商业化运营，不能够算商业化产品的范畴,我们会走agent，会做一个总结，在评估的时候会缀上去，来提高效果。，比如“我认为这份简历应该通过，因为候选人的这个项目经验很亮眼”。</mark>这些高质量的反馈数据会成为我们为该客户持续优化模型和筛选规则的宝贵资产，让系统越来越懂他的偏好。

通过这三步，我们把“效果好”从一个主观感受，变成了一个可量化、可解释、可持续提升的客观标准。

### 2. 你既然说简历那么多，那hr直接在平台上搜索是不是效果就足够好了？？这个想问的是AI筛选简历的必要性

这是一个非常好的问题，它触及了我们产品的核心价值：我们做的不是“搜索”，而是“筛选”，是**传统关键词搜索的全面升级**。

1.  **语义理解 vs. 关键词匹配：** 传统搜索依赖于 HR 输入的关键词，比如“Java”。但如果一个优秀的候选人简历上写的是“精通 Spring 全家桶、熟悉 JVM 底层原理”，但没有明确写“Java”这个词，他就可能被漏掉。我们的大模型具备深度语义理解能力，能理解技能、项目经验和岗位要求之间的深层关联，而不是停留在字面匹配。

2.  **多维度复杂条件 vs. 简单逻辑组合：** 招聘需求往往是复杂且多维度的，例如“需要一个有5年以上经验，其中至少2年带过团队，最好有电商背景，并且熟悉高并发架构的Java专家”。这种复杂组合很难用简单的“AND/OR”搜索来精确表达。而我们的 Agent 恰恰擅长将这种复杂的自然语言需求拆解为多个维度，并对每个维度进行独立且精准的评估。

3.  **效率革命：从“大海捞针”到“提供 shortlist”：** 关键词搜索的结果仍然是海量的简历列表，HR 依然需要一份一份地点开、阅读、判断，工作量巨大。我们的系统完成的是从简历解析、信息提取、多维度打分、规则匹配到生成报告的全流程自动化。最终交付给 HR 的，是一个已经排好序的、高质量的-候选人短名单（shortlist），极大地提升了筛选效率。

4.  **标准统一与公平性：** 人工筛选会受到 HR 的精力、情绪、甚至偏见的影响，标准可能会摇摆。AI 则能保证对每一份简历都采用完全一致、客观的标尺去衡量，保证了筛选过程的公平性和一致性。

所以，传统搜索只能解决“找出来”的问题，而我们解决的是“选出来”的问题，这在效率和质量上是质的区别。

## 模型实现方面

### 1. 为啥要沟通实现这个过程，直接让用户填表不更好吗？

我们选择对话式 Agent 而不是传统表单，主要基于以下三点考虑：

1.  **用户没有这个耐心填表，沟通的交互很好：** 填表用户会让你滚的。

2.  **引导用户说出想说的：** 有时候，HR 自己对岗位的画像也不是 100% 清晰的。<mark>一个优秀的 Agent 在这里可以扮演“招聘专家顾问”的角色。例如，当 HR 提出需要“商业化经验”时，Agent 可以追问：“我们具体是指 B 端还是 C 端的商业化经验？对项目的营收规模有要求吗？</mark>” 通过这种互动，Agent 能够帮助 HR 挖掘和澄清需求，共同定义出一个更精准、更合理的岗位画像。

总而言之，表单交付的是“信息”，而对话交付的是“理解”。在招聘这个高度依赖经验和沟通的场景里，“理解”远比“信息”更有价值。

### 2. 拆维度，你们是怎么想到拆维度的？？一把梭的方案跟他比差在哪，这个变化过程是怎样的？

我们之所以坚决选择“拆分维度”的方案，而放弃“一把梭”的黑盒方案，是经过了深入的实践和思考，核心原因在于**可解释性、可控性和可维护性**。

**“一把梭”方案的问题：**
“一把梭”方案，就是直接把简历和岗位描述（JD）丢给一个大模型，问它“这俩匹配吗？打个分”。这个方案最大的问题是它是一个“黑盒”。
*   **不可解释：** 它只会告诉你“不匹配”，但不会告诉你**为什么**不匹配。是因为学历不够？还是经验年限不足？或者是技术栈有差异？HR 无法理解和信任这个结果。
*   **不可控：** HR 无法对筛选标准进行微调。比如，他们可能想临时放宽对学历的要求，或者提高对某个特定技术栈的权重。在“一把梭”方案里，这几乎是不可能实现的。
*   **调试困难：** 一旦效果不好，你完全不知道该如何去优化。是模型本身不行？还是 Prompt 没写好？问题无法定位。

**我们方案的演进过程和“拆分维度”的优势：**
我们的项目初期也尝试过类似“一把梭”的简单方案，但很快就遇到了上述瓶颈。我们意识到，人类专家筛选简历的过程，本身就是一个“多维度评估”的过程。于是，我们把 AI 的工作流程改造成模拟人类专家的思考方式：

1.  **需求解构：** 将模糊的岗位需求，解构成一系列清晰、独立、可评估的维度（如学历、工作年限、技术栈、项目经验等）。
2.  **逐一评估：** 针对每一个维度，让模型去简历中寻找相应信息并进行评估和打分。
3.  **综合决策：** 根据预设的规则，结合所有维度的得分，做出最终的判断。

这个方案的优势恰好解决了“一把梭”的所有痛点：
*   **完全可解释：** 每一份简历的报告都会清晰展示在各个维度上的得分情况，HR 对结果一目了然，知其然且知其所以然。
*   **高度可控：** HR 可以像玩策略游戏一样，随时调整不同维度的权重和筛选门槛，让筛选标准完全符合他们当下的业务需求。
*   **易于维护和迭代：** 如果发现“学历”维度的识别总是不准，我们就可以集中力量去优化这一个点的模型或 Prompt，问题定位非常精准，迭代效率高。

从“一把梭”到“拆分维度”，是我们从追求“能用”到追求“好用”和“可靠”的关键一步，它让我们的系统从一个黑盒玩具，变成了一个真正可信赖的专业工具。

### 3. 你能举例子说一下，不同的职位有哪些维度吗？？

当然，维度的设定是高度定制化的，会根据职位的不同而有很大差异。这里举几个典型的例子：

**职位一：Java 后端高级工程师（搜索方向）**

这是一个很好的例子，来说明我们的维度抽取如何处理复杂的、带有权衡逻辑的招聘需求。假设 HR 想要一个搜索方向的专家，他在沟通中可能会说：“我最想要有搜索或 RAG 经验的人，但如果候选人学历很好，或者后端基础特别扎实，或者对 AI 很了解，那没有直接经验也可以考虑。”

在这种场景下，Agent 抽取的维度会分为几个层次：

*   **核心期望维度：**
    *   `搜索开发经验` (如：Elasticsearch, Solr, Lucene 的实践经验)
    *   `RAG 项目经验` (检索增强生成相关项目经验)
*   **补偿性维度 (Compensatory Dimensions):**
    *   `学历背景` (如：是否为顶尖院校的硕士或博士)
    *   `后端综合能力` (体现 Java 基础、并发、框架应用等的扎实程度)
    *   `AI 领域知识` (对机器学习、NLP 等有深入了解)
*   **基础门槛维度：**
    *   `工作年限`
    *   `团队协作能力`

这个例子最关键的一点在于，它直接影响了 **`筛选规则`** 的生成。Agent 不会生成一个简单的“必须满足 A 和 B”的脚本，而是会生成一个包含复杂条件判断和权衡逻辑的 `Groovy` 脚本。这个脚本会体现出规则的“拼凑”与权衡，例如：

```groovy
// 伪代码示例
if ( getScore("搜索开发经验") >= 80 || getScore("RAG 项目经验") >= 80 ) {
    return "非常推荐";
} else if ( getScore("后端综合能力") >= 90 && getScore("学历背景") >= 90 ) {
    return "推荐"; // 后端基础和学历可以补偿核心经验的不足
} else if ( getScore("后端综合能力") >= 80 && getScore("AI 领域知识") >= 80 ) {
    return "推荐"; // 后端基础和AI知识也可以补偿
} else {
    return "一般";
}
```

这正是我们 Agent 区别于简单填表系统的核心优势：它能够理解并实现这种复杂的、带有业务权衡的招聘策略。

**职位二：产品经理（电商方向）**
*   **硬性门槛维度：** `学历`、`产品经验年限`。
*   **专业技能维度：**
    *   `行业领域经验` (是否有电商，特别是C端电商的核心模块经验，如交易、营销、供应链)
    *   `项目经验类型` (是否有从0到1搭建产品，或负责核心增长指标的经验)
    *   `数据分析能力` (是否能熟练使用SQL、BI工具，并通过数据驱动决策)
    *   `用户研究与需求分析`
*   **软性能力维度：**
    *   `逻辑思维与结构化表达`
    *   `沟通协调与资源整合能力` (推动开发、设计、运营团队协作)

**职位三：销售总监（SaaS 行业）**
*   **硬性门槛维度：** `行业经验年限`、`团队管理规模`。
*   **业务能力维度：**
    *   `过往销售业绩` (历史年单完成率、客单价等)
    *   `行业客户资源` (在特定行业，如金融、零售，是否有深厚的人脉积累)
    *   `销售方法论` (是否具备体系化的销售打法和团队赋能能力)
    *   `市场洞察与战略规划`
*   **软性能力维度：**
    *   `领导力与团队激励`
    *   `谈判与公关能力`

这些例子可以看出，我们的维度设计是深入业务的，它把一个岗位的要求，拆解成了若干个可衡量、可评估的能力项。

### 4. 维度，你说足够细致，问题来了，模型提取的维度你怎么知道他一定是合理的？？比如用户写了redis，kafka，mysql这样的，难道redis，kafka，mysql这都算三个维度？？

这个问题非常专业，确实是我们系统设计的关键点之一。我们通过“**分层与聚类**”和“**人机协同确认**”两个机制来确保维度的合理性。

1.  **分层与聚类，避免维度爆炸：**
    我们不会简单地把用户提到的每个技术名词都设为一个独立维度。我们的 Agent 内置了对技术、技能领域的知识图谱。当它识别到 `redis`, `kafka`, `mysql` 这类词时，它会自动进行语义聚类和分层。
    *   它会首先创建一个更高阶的维度，例如 `后端技术栈` 或 `中间件与数据库`。
    *   然后，在这个高阶维度下，再把 `redis` (缓存技术), `kafka` (消息队列), `mysql` (关系型数据库) 作为具体的**评估点**或**子维度**。

    这样做的好处是，既能保证评估的细致度，又不会让维度列表变得过于冗长和琐碎，保持了良好的结构性和可管理性。

2.  **人机协同确认，确保维度符合用户意图：**
    AI 自动生成的维度结构只是一个“草案”。最关键的一步是，Agent 会把这个结构化的维度草案**返还给用户进行确认**。
    例如，它会这样跟 HR 沟通：
    > “根据您的描述，我为您生成了以下的招聘维度结构：
    > *   **核心维度：中间件与数据库**
    >     *   评估点1：Redis 使用经验
    >     *   评估点2：Kafka 使用经验
    >     *   评估点3：MySQL 调优能力
    > 您看这样划分是否合理？或者您希望将其中某一项作为更独立的、权重更高的维度来考察吗？”

    通过这个交互确认的环节，我们把 AI 的结构化能力和人类专家的业务判断结合起来，最终确保了维度的设置既专业合理，又完全符合用户的真实意图。

技术栈不要细致拆解（提示词控制）
提示词，让AI能够归类一下这个维度。


### 5. 你们为什么在建模的时候选择Claude？评估的时候选择豆包？那claude把你们封了，你们是不是就建不了模了？？

这是个关于我们技术选型和架构鲁棒性的好问题。我们采用多模型策略，是出于“**因材施教**”和“**风险控制**”的双重考虑。

1.  **因材施教——为不同任务选择最合适的模型：**
    *   **建模阶段（用 Claude）：** 这个阶段的核心任务是与用户进行深度对话，理解复杂的、个性化的招聘需求，并将其转化为结构化的维度和规则。这个任务对模型的**逻辑推理、复杂指令遵循和生成能力**要求极高。在我们的测评中，像 Claude 3 Opus 或 GPT-4o 这样的顶级模型在这个“高难度推理”任务上表现最好，能够生成最精准、最合理的维度。
    *   **评估阶段（用豆包）：** 这个阶段是高并发的生产环节，需要处理成千上万份简历。其核心任务是根据已经定义好的维度，去简历中进行**信息提取和分类**。这个任务相对更标准化，对成本和响应速度（TPS）非常敏感。像豆包、Kimi 或者一些 fine-tune 过的开源模型，在这些任务上已经能做得很好，并且具备极高的性价比。

    简单来说，我们用“博士生”（Claude/GPT-4o）来做最难的“课题研究”（建模），用“本科生”（豆包/Kimi）来做大量的“批改作业”（简历评估），实现了资源的最优配置。

2.  **风险控制——通过抽象层避免厂商锁定：**
    我们从架构设计之初就考虑到了对单一模型供应商的依赖风险。我们在业务逻辑和底层大模型之间构建了一个**模型抽象层（Model Abstraction Layer）**。
    *   所有的业务调用，都不是直接请求某个具体的模型 API，而是请求我们内部的抽象接口，例如 `generate_dimensions(conversation)`。
    *   这个抽象层负责管理和路由到底层应该使用哪个模型。我们可以通过简单的配置，就将建模任务从 Claude 切换到 GPT-4o、阿里的通义或百度的文心。

    我们持续对市面上的主流模型进行 benchmark，确保我们始终有可靠的备选方案。所以，即便某个供应商出现问题，我们也能在短时间内平滑切换，保证业务的连续性和稳定性。

### 6. 你说到kimi-k2出来的时候，你们换了发现效果不好，效果不好在哪？？你能举例子吗？

主要是生成的不规范的问题，你会发现明显在生成代码的比如筛选规则这一步是，他是生成多端的groovy脚本，这个过程，明显就是Claude会更好，其他的都不好。不好的意思就是失败率很高。

非thinking的模型，语义的描述，问题a：对你提示词细节会漏掉，会扭曲数字的描述， 
b：k2,描述理解，没提毕业时间，没提到的话不应该算作不通过。但是K2会认为没提及给你不通过
已经标了工作时长，分档的理由，k2说读到了37个月，37个月不满足3年。而且频繁。

但是思考的模型不够拟人，这个地方正在改进
最近尝试：
1. 拆分出维度的结构的改动：（维度分档表）思考链：提示词里构造显式的思考链
    {
      "dimension": "家具商品运营经验时长",
      "is_new": false,
      "description": "家具商品运营经验时长（除了定义之后，如何思考这个事情，1. 首先什么是家具运营经验，2. 从经验中选择出对应的经历，3.计算过程    思考的SOP ）",
      "levels": [
        {
          "level_name": "3档", 
          "score_range": "90-100分",
          "description": "中共党员，政治素养优秀"
        },
        {
          "level_name": "2档",
          "score_range": "60-89分", 
          "description": "共青团员或群众，简历未提及政治面貌时默认为本档位"
        },
        {
          "level_name": "1档",
          "score_range": "0-59分",
          "description": "其他党派或政治背景，需具体评估"
        }
      ]
    }
2. 评估的过程的提示词：你要去参考那个思考链，去评估这样的
论文：提示词中构造思考过程，具有显著提升思考链。
（多重步骤的判断是可以走这样过程： 符合某种要求经验的总时长）


### 7. 你们做的任何改动，怎么评估他效果会更好？难道只是跑100份案例？？万一只是针对这个客户效果好，下个客户效果差呢？？

我们有一套立体化的、从线下到线上的评估体系，来确保任何改动的有效性和泛化能力，绝不仅仅是跑 100 个 case。

1.  **线下黄金评测集（Golden Test Set）：**
    我们维护了一个高质量、多样化的“黄金评测集”。这个评测集包含：
    *   **多样化的岗位：** 覆盖技术、产品、销售、运营等多个主流岗位。
    *   **多样化的简历：** 包含格式规整的、排版混乱的、内容详实的、信息简略的各类简历。
    *   **精心标注的答案：** 每一份简历针对不同的维度，都有由人类专家精细标注的“标准答案”。
    *   **典型的 Edge Cases：** 专门收集了各种容易出错的案例，如多段重叠的实习经历、中英文混杂的技能描述等。

    任何模型的更新、Prompt 的优化，都必须先在这个黄金评测集上进行回归测试，确保各项核心指标（准确率、召回率）不下降，甚至有提升。

2.  **A/B 测试与线上小流量验证：**
    线下评测通过后，我们会进行线上 A/B 测试。我们会将线上真实流量的一小部分（例如 5%）切到新模型或新策略上，同时老版本继续服务 95% 的流量。我们会观察和对比新老版本在真实业务场景中的核心指标，例如：
    *   **HR 修正率：** 新版本的 AI 判断结果，被 HR 手动修正的比例是否降低了？
    *   **筛选通过率：** 是否出现了不合理的通过率剧烈波动？
    *   **用户满意度反馈：** 通过问卷等形式收集试用新功能用户的直接反馈。

3.  **客户维度的效果监控：**
    我们理解不同客户有不同的招聘偏好。因此，我们的监控系统也是按客户维度进行细分的。我们会特别关注新策略在不同行业、不同规模的客户群体上的表现是否一致。如果发现新策略只对某些客户效果好，而对另一些客户有负向影响，我们会深入分析原因，可能会选择将这个改动作为一种可配置的“策略”，让客户按需开启，而不是“一刀切”地全量上线。

通过**“线下黄金集保下限，线上A/B测试看上限，分客户监控保泛化”**这套组合拳，我们能科学、严谨地评估每一次改动，确保其带来的价值是普适和可靠的。

### 8. 你们判断筛选规则是正确的？？这一步的东西也是大模型输出的吗？


### 9. 我感觉你们这个有点空，就比如说，现在跟客户的一致率不一致。究竟是维度的问题，还是筛选规则的问题呢？？？怎么判断

这是一个非常切中要害的诊断问题。当 AI 的判断和客户不一致时，我们有一个系统性的 **归因分析（Attribution Analysis）** 流程来快速定位问题根源。这正是我们“拆分维度”架构的优势所在。

假设 AI 淘汰了一份简历，而 HR 认为应该通过。我们的诊断流程如下：

1.  **第一步：检查“维度评分”环节。**
    我们会立刻调出这份简历的分析报告，报告上会清晰地展示 AI 对每一个维度的评分结果。我们会和 HR 一起核对：
    *   **信息提取是否准确？** 比如，简历明明写了5年经验，AI 是否错误地识别成了3年？
    *   **评分标准是否合理？** 比如，对于“商业化经验”这个维度，AI 将“参与过一个百万用户产品的增长活动”评为“入门”档，而 HR 认为这至少应该是“熟练”档。
    
    如果在这个环节发现了偏差，那么问题就出在**维度评分模型**上。我们可能需要优化这个维度的 Prompt，或者用更多案例去 fine-tune 模型对这个维度的理解。

2.  **第二步：如果维度评分都准确，则检查“筛选规则”环节。**
    如果在上一步中，HR 认同 AI 对所有维度的评分（比如，学历‘本科’，经验‘5年’，商业经验‘熟练’……），但最终的“淘汰”结论他却不认同。
    
    那么问题就非常明确地出在**筛选规则**上。很可能是当前的规则设置得过于严苛了。比如，规则里写着“商业化经验”和“高并发经验”必须**同时**达到“熟练”，而 HR 的真实意图是**满足其一**即可。
    
    这时，HR 就可以直接在我们的系统里，将这条规则的逻辑从 `AND` 修改为 `OR`，问题立刻就解决了。

通过这样一个从“**评分**”到“**规则**”的逐层排查，我们能够非常精准、高效地定位到不一致的根本原因，并进行针对性的调整。这让我们的系统不再是一个模糊的、不可捉摸的黑盒，而是一个清晰、透明、可调试的诊断系统。

## 模型稳定性

### 1. 你们怎么评估每个阶段的效果？

我们将整个 Agent 工作流拆分为三个核心阶段，并为每个阶段设立了独立的、可量化的评估指标和评测集。

1.  **阶段一：需求理解与维度拆解**
    *   **任务：** 将用户与 Agent 的对话，转化为结构化的招聘维度。
    *   **评估方式：** 我们有一个“对话-维度”的评测集。我们会找真实的 HR 进行对话，然后由人类专家手工标注出最合理的维度结构作为“标准答案”（Ground Truth）。
    *   **评估指标：**
        *   **维度覆盖率（Recall）：** 模型生成的维度是否覆盖了所有关键的招聘需求点？
        *   **维度准确率（Precision）：** 模型生成的维度是否都是合理且必要的，有没有产生幻觉或无关的维度？
        *   **结构合理性：** 由人类专家对生成维度的层级、颗粒度进行打分。

2.  **阶段二：简历信息提取与维度评分**
    *   **任务：** 针对每一个确定的维度，从简历中提取信息并给出评分。
    *   **评估方式：** 这是我们最核心的“黄金评测集”发挥作用的地方。这个评测集包含了上千份简历，每一份简历的每一个维度都有人类专家标注好的标准答案（比如，这份简历的“工作年限”就是“4.5年”，对应的档位是“3-5年”）。
    *   **评估指标：**
        *   **准确率（Accuracy）：** 模型评分和标准答案一致的比例。
        *   **鲁棒性测试：** 在各种格式混乱、表述不清的简历上的表现。
        *   **一致性测试：** 将同一份简历的内容打乱顺序或微调措辞，看模型的输出是否保持稳定。

3.  **阶段三：报告与理由生成**
    *   **任务：** 基于筛选结果，生成可读性高、逻辑清晰的推荐或淘汰理由。
    *   **评估方式：** 采用人工评估和模型评估（Model-based Evaluation）相结合的方式。
    *   **评估指标：**
        *   **逻辑清晰度：** 生成的理由是否和维度的评分结果强相关？
        *   **语言流畅度：** 文本是否自然、专业？
        *   **事实一致性：** 理由中引用的简历内容是否准确无误？

通过对每个阶段进行独立的、精细化的评估，我们能确保整个系统的端到端效果是建立在每一个环节都稳健可靠的基础之上的。


1. 根据jd生成画像：是否能够过滤掉具体的技术细节，
2. 去把四句话转成md: 这个判断的是准确度，这个格式是否完善。每个维度是否能拆成一列
3. 业务的评估：产品来做，

不一致：维度少了，人工添加一下，一自律高了，拆维度的提示词。影响别的职位，别的案例怎么办？
1. 全量跑一些经典案例
2. 我灰度部分用户测试

1. 四档分档：
2. 维度拆分
3. 简历解析
4. AI评估

1. 基建的部分：四档分档和简历解析，这跟个性化客户都无关。对客之前都搞好
2. 基本稳定性判断：2. 维度拆分，评分标准是啥 （颗粒度的侧重），
3. 维度的拆分和分档 + 筛选规则：拿到badcase之后去调优，是哪个维度跟人理解的gap在哪里，增加一些提示词或者。这个跟每一家个性化的内容。



不同的提示词，不同的判断策略 ---- 
1. 输入一个提示词，根据提示词分析这个提示词的意图，给出这个提示词做测试需要关注哪些方面，人工介入的流程补充一下这个评估标准。输入你觉得对的业务的评估标准。生成一个结构化的评估的结构表。
提示词：评测表 + 用例 + 标准用例  ---> 新问题还是已有维度问题，符不符合预期，看看在哪一个维度上有问题

<mark>把言语的描述转化为标签，言语的标签转化为数字</mark>


### 2. 换模型后你们怎么评估每一段的效果？

更换底层大模型是一项核心变更，我们的评估流程会比常规优化更严格，确保新模型能在我们系统的每一个环节上都达到甚至超越旧模型。

这个过程可以概括为“**三层漏斗式评估**”：

1.  **第一层：通用能力基准测试（Broad Benchmark）**
    在集成到我们业务流之前，我们会先用公开的通用能力评测集（如 SuperCLUE, MMLU 等）对新模型进行一轮基础能力考察，确保它在推理、代码、语言理解等基础素质上没有明显短板。

2.  **第二层：我们业务场景的离线评测（Offline Evaluation）**
    这是最核心的一步。我们会把新模型接入到我们上一题提到的三个阶段的评测流程中，用我们自己积累的“黄金评测集”去全面“拷问”它：
    *   **在“维度拆解”任务上：** 新模型的准确率和召回率对比旧模型是提升了还是下降了？
    *   **在“维度评分”任务上：** 新模型在所有细分维度上的评分准确率如何？在处理我们专门设计的 Edge Cases 时表现是否更稳定？
    *   **在“理由生成”任务上：** 新模型生成的报告，在逻辑性和流畅度上的得分如何？

    我们会进行详细的 side-by-side 对比，只有新模型在**我们关心的所有核心指标上全面超越或持平**旧模型，它才有资格进入下一轮。

3.  **第三层：线上小流量 A/B 测试（Online A/B Testing）**
    通过所有离线评测后，我们会把新模型部署到线上，并切分一小部分流量（例如 1%-5%）给它。我们会密切监控新旧模型在线上真实流量下的表现差异，关注的核心业务指标包括：HR 对结果的修正率、API 响应耗时、调用成本、以及用户的满意度反馈等。

只有经过这三层严格的、从线下到线上的漏斗式筛选，我们才会最终决定是否进行模型的全量切换。这确保了我们每一次模型升级，都是一次真正意义上的“进化”。

### 3. 模型中间某一步幻觉了，是不是会造成后面的巨大的问题，怎么办呢？

这是一个非常关键的容错问题。确实，在一个链式（Chain-of-Thought）的 AI 系统中，任何一步的幻觉都可能导致“一步错，步步错”的雪崩效应。我们设计了三重防御机制来缓解和控制这个问题：

1.  **第一道防线：通过 Prompt Engineering 约束模型**
    我们在每个环节的 Prompt 中都加入了严格的约束指令，以降低幻觉的概率。
    *   **指令明确：** 我们会明确告知模型“如果简历中没有找到相关信息，请明确回答‘未提及’，而不是猜测或推断”。
    *   **溯源要求（Groundedness）：** 我们要求模型在给出结论时，必须同时引用简历中的原文（Quote）作为证据。例如，在判断“学历”时，它不仅要输出“本科”，还要附上从简历中提取的“毕业院校：XX大学 | 专业：计算机科学 | 学历：本科”这段原文。这使得幻觉很容易被校验出来。

2.  **第二道防线：设置独立的校验环节（Verification Step）**
    对于一些特别关键、且容易出错的环节，我们会设计一个独立的、更简单的模型或规则来进行交叉验证。
    *   **例如，在“工作年限”计算上：** 我们有一个模型负责从简历中提取所有的工作经历起止时间。在它完成提取后，我们不会直接相信它的结果，而是会有一个非常简单的、基于规则的程序来校验这些时间段的合法性（比如结束时间不能早于开始时间），并进行求和计算。这个校验器就像一个“审计员”，它不负责复杂的提取，只负责对提取出的结果进行“质检”。

3.  **第三道防线：人机交互的最终确认**
    如前所述，我们系统里最关键的决策点，比如**维度的最终确认**和**筛选规则的最终确认**，都必须经过 HR 的人工审核。这构成了我们最后，也是最重要的一道防线。即使模型在中间步骤产生了某些幻觉，在这些关键的人机交互节点上，它也会被人类专家发现并纠正，从而避免了错误被传递到最终的筛选环节。

通过这三道防线的层层设防，我们虽然不能 100% 杜绝幻觉的发生，但可以极大地降低其发生概率，并在其发生时能够及时发现和拦截，确保它不会对最终的筛选结果造成灾难性的影响。 


## 最终

### 1. 你觉得还有哪些地方可以改进？
1. 如果我们要走一个通用的垂直领域manus，我们完全做到比如，把我们中间的某些流程给抽出来。假如有些客户，仅仅只是想要解读简历这个功能，我们把当前supervisor合并成一个建模的agent，同时把简历增强的模块，抽出一个单独的agent。让能够实现就是比如我们给他简历解析，打标和配上专有知识。这个过程会很有用

2. 典型模板提供，你是个小公司，你可以直接选择某个大公司的商业化简历筛选的模板

3. 技术上来讲，现在实现都是靠，java和litellm和dify一起实现的。因为我对langgraph也有了解，所以我觉得可以用langgraph可以试着做一些事情，比如人机交互这件事，langgraph的实现其实更容易一些。但是我们用java来实现就是靠着订一个工具来做的

4.  --- 筛选准确率不如贝洛。硬条件的解析不够准，所有的环节都是大模型，工程侧和数据侧数据积累很少。固定化的标签积累的少。
-- 运营岗：xxx运营岗，xxx行业，行业也会细分
-- 各行各业的标签 --- 非常多

时好时坏，用的ai弯道超车。打一部分 

### 2. 你这个项目看起来不够复杂
1. 这是我参与最多的地方，有一些区域是我完全不了解的。比如根据简历评估后，是需要进行微聊的，就是给候选人打招呼这件事，你需要要到真正简历。而且你可以根据风险点进行一些轻微的聊天。他们有复杂的回复策略
2. 我这里是建模和解析 + 评估，还有阶段是简历的爬取那部分。就是到我这里的时候，这个简历已经传给我了，比如他们会借鉴平台上的搜索功能，搜出简历，我会给他们提供评估的接口，让他们判断这个搜索词是否有效。有效的话，他们会翻页，而且他们有策略从新生成搜索词，搜简历和收到简历，等等这些流程。
3. 拟人化策略，有人在搞，举个例子就是你的鼠标该怎么做，你的行为如何。但又不能完全让大模型来做，这里面也很复杂。