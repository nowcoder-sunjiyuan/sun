# 简历微服务项目分库分表深度解析

<details>
<summary><strong>目录</strong></summary>

- [1. Sharding-JDBC 核心原理剖析](#1-sharding-jdbc-核心原理剖析)
  - [Sharding-JDBC 是什么？](#sharding-jdbc-是什么)
  - [它的工作原理是怎样的？](#它的工作原理是怎样的)
- [1.1 SQL查询的完整链路与Sharding-JDBC的切入点 (新增章节)](#11-sql查询的完整链路与sharding-jdbc的切入点-新增章节)
  - [一条标准SQL的生命周期（无Sharding-JDBC）](#一条标准sql的生命周期无sharding-jdbc)
  - [Sharding-JDBC如何“劫持”查询？](#sharding-jdbc如何劫持查询)
  - [广播路由的并发执行机制](#广播路由的并发执行机制)
- [2. 从单表到分表的平滑迁移方案 (Zero-Downtime Migration)](#2-从单表到分表的平滑迁移方案-zero-downtime-migration)
  - [第一阶段：准备工作](#第一阶段准备工作)
  - [第二阶段：数据同步](#第二阶段数据同步)
  - [第三阶段：正式割接 (The Cutover)](#第三阶段正式割接-the-cutover)
  - [第四阶段：下线老逻辑](#第四阶段下线老逻辑)
- [3. Sharding Key (`resume_id`) 合理性深度分析](#3-sharding-key-resume_id-合理性深度分析)
  - [`resume_id` 作为分片键的合理性（优点）](#resume_id-作为分片键的合理性优点)
  - [`resume_id` 作为分片键的挑战（缺点）](#resume_id-作为分片键的挑战缺点)
  - [解决方案与权衡](#解决方案与权衡)
- [4. 水平分表 vs. 垂直分表](#4-水平分表-vs-垂直分表)
- [5. 其他可能遇到的分库分表问题 (Bonus Interview Questions)](#5-其他可能遇到的分库分表问题-bonus-interview-questions)

</details>

## 1. Sharding-JDBC 核心原理剖析

面试官问 “Sharding-JDBC 是什么” 时，他想听到的不仅仅是“一个分库分表的中间件”，而是你对它工作原理的理解。

### Sharding-JDBC 是什么？

Sharding-JDBC 是一款**增强型的JDBC驱动**，它在 Java 的 JDBC 层提供分库分表、读写分离、数据脱敏等功能。对应用开发者来说，它最大的优点是**透明化**和**轻量化**。

- **透明化**：你引入它的 starter 依赖和配置后，几乎可以像操作单库单表一样使用 `MyBatis`、`JPA` 等 ORM 框架，Sharding-JDBC 会自动帮你处理 SQL 的路由、改写和结果归并。
- **轻量化**：它以 `jar` 包形式运行在你的应用进程内，没有额外部署和运维成本，不像 `Mycat` 这类代理层方案需要额外部署一个中间件服务。

### 它的工作原理是怎样的？

当你通过 MyBatis 执行一条 SQL 语句时，Sharding-JDBC 会“劫持”这次调用，然后执行一套精密的核心流程：

```text
[ 你的应用 (MyBatis/JPA) ]
          |
          v
[  原始SQL: SELECT * FROM resume_basic WHERE resume_id IN (1, 2) ]
          |
          v
+---------+------------------------------------------------------+
|         |                  Sharding-JDBC 内部流程                  |
|         +------------------------------------------------------+
|         |
|         |  1. SQL 解析 (SQL Parsing)
|         |     - 将SQL文本解析为抽象语法树(AST)
|         |
|         |  2. SQL 路由 (SQL Routing)
|         |     - 根据分片键(resume_id)和分片算法(取模)
|         |     - 计算出SQL需要发往哪些物理表
|         |       - resume_id=1 -> resume_basic_1
|         |       - resume_id=2 -> resume_basic_2
|         |
|         |  3. SQL 改写 (SQL Rewriting)
|         |     - 将逻辑表名替换为物理表名
|         |       - "FROM resume_basic" -> "FROM resume_basic_1"
|         |       - "FROM resume_basic" -> "FROM resume_basic_2"
|         |
|         |  4. SQL 执行 (SQL Execution)
|         |     - 通过内部线程池并发执行多个改写后的SQL
|         |       - Connection 1 -> 执行 targeting resume_basic_1 的SQL
|         |       - Connection 2 -> 执行 targeting resume_basic_2 的SQL
|         |
|         |  5. 结果归并 (Result Merging)
|         |     - 将来自 resume_basic_1 和 resume_basic_2 的结果合并
|         |     - (如果需要，还会进行排序、分页、聚合等)
|         v
+---------+
          |
          v
[  最终结果集返回给你的应用  ]
```

1.  **SQL 解析 (SQL Parsing)**：首先，它会把接收到的 SQL 语句解析成一个**抽象语法树 (AST)**。这一步非常关键，因为它能精确地理解 SQL 的意图。
    -   **解析细节**：这个过程和 MySQL 自身的解析器原理类似，都是词法分析、语法分析，最终生成一个结构化的树形对象（AST）。Sharding-JDBC 使用了像 ANTLR 这样的业界成熟的解析器生成工具，为多种数据库方言（MySQL, PostgreSQL等）定制了语法规则。有了AST，它就能以编程方式轻松地获取表名、`WHERE`条件、`ORDER BY`字段等关键信息，而无需用正则表达式等不稳定的方式去“猜”。

2.  **SQL 路由 (SQL Routing)**：解析完成后，Sharding-JDBC 会根据你的分片配置（`sharding-column` 和 `algorithm-expression`）和 SQL 中的分片键的值，计算出这条 SQL 应该路由到哪个（或哪些）真实的物理表。
    -   例如，`SELECT * FROM resume_basic WHERE resume_id = 123`，它会根据 `123 % 32` 的结果，确定这条 SQL 应该发往 `resume_basic_11` 这张表。
    -   如果 `WHERE` 条件中没有分片键，比如 `SELECT * FROM resume_basic WHERE user_id = 456`，它会认为这是一次**广播路由 (Broadcast Routing)**，会将 SQL 发往**所有32张分表**。

3.  **SQL 改写 (SQL Rewriting)**：确定了物理表后，它会重写原始的 SQL。最简单的改写就是把逻辑表名替换成物理表名。例如，把 `FROM resume_basic` 改写成 `FROM resume_basic_11`。

4.  **SQL 执行 (SQL Execution)**：通过真实的数据库连接池，在多线程中并发地执行改写后的 SQL 语句。

5.  **结果归并 (Result Merging)**：
    -   如果 SQL 只路由到单个分片，那么结果直接返回即可。
    -   如果是广播路由，它会收到来自多个分片的结果集。这时，它需要像数据库一样，对这些结果进行**合并、排序、分页、聚合**等操作，然后将最终处理好的结果集返回给你的应用程序。

**总结**：你之所以只加一个 starter 和一些配置就能工作，是因为 `sharding-jdbc-spring-boot-starter` 自动装配了上述所有核心组件。它会读取你的 `application.yml` 配置，自动创建数据源、分片策略，并替换掉默认的 `DataSource`，使得整个过程对上层应用代码完全无感知。

---

## 1.1 SQL查询的完整链路与Sharding-JDBC的切入点 (新增章节)

要理解Sharding-JDBC的威力，首先要清楚一条普通的SQL查询经历了怎样的旅程，以及Sharding-JDBC是在哪个环节进行“拦截”的。

### 一条标准SQL的生命周期（无Sharding-JDBC）

假设你的代码执行了 `resumeBasicMapper.selectById(123)`，这个过程大致如下：

1.  **应用层 (MyBatis)**：MyBatis 根据Mapper接口和XML配置，生成最终的SQL语句 `SELECT * FROM resume_basic WHERE resume_id = 123`。

2.  **数据源层 (HikariCP)**：应用向**数据源(DataSource)**请求一个数据库连接。这里的`DataSource`其实是一个**数据库连接池**（比如HikariCP）。它的核心作用是预先创建并管理一批数据库连接，避免了每次查询都重新建立TCP连接的巨大开销。你可以把它理解成一个“数据库连接的管理器”。

3.  **JDBC驱动层**：应用拿到连接后，通过标准的**JDBC API**，将SQL语句发送给JDBC驱动（例如 `mysql-connector-java.jar`）。

4.  **网络传输层**：JDBC驱动会将SQL语句和参数，按照**MySQL的专属通信协议**进行编码，然后通过TCP/IP网络Socket发送给MySQL服务器的监听端口（默认3306）。**注意，这里不是HTTP请求**，而是数据库厂商私有的、更高性能的二进制协议。

5.  **MySQL服务层**：
    *   **连接/线程处理器**：MySQL为每个连接分配一个线程来处理后续所有请求。
    *   **查询解析与优化**：MySQL Server层的解析器对SQL进行解析、优化，并生成执行计划。
    *   **执行器**：调用存储引擎的接口去执行计划。

6.  **MySQL存储引擎层 (InnoDB)**：
    *   InnoDB引擎根据执行计划，在它的存储文件 (`.ibd`) 中查找数据。它会先在自己的内存缓冲池 (`Buffer Pool`) 中查找，如果找不到再去磁盘加载，并负责处理事务、锁等底层操作。

### Sharding-JDBC如何“劫持”查询？
Sharding-JDBC巧妙地将自己插入到了**数据源层**。

`sharding-jdbc-spring-boot-starter` 会自动装配，用它自己实现的 `ShardingSphereDataSource` **替换**掉你配置的原始 `HikariDataSource`。

所以，现在你的应用的查询链路变成了：

**应用层 -> ShardingSphereDataSource -> [Sharding-JDBC核心流程] -> 真实的HikariDataSource -> JDBC -> MySQL**

**Sharding-JDBC就成为了一个位于“你的代码”和“真实数据库连接池”之间的代理层。**

> **知识点延伸：MyBatis如何将接口调用转换为SQL？**
> 这是一个非常好的问题，它涉及到MyBatis框架的核心设计。简单来说，它利用了**动态代理 (Dynamic Proxy)** 和 **反射 (Reflection)**。
> 1.  **启动时解析与注册**：应用启动时，MyBatis会扫描所有Mapper接口和对应的XML/注解，为每一个SQL语句创建一个`MappedStatement`对象（包含了SQL、参数类型、返回类型等全部信息），并将其注册到一个全局的配置中心，Key是`接口全限定名 + 方法名`。
> 2.  **注入时创建代理**：当你`@Autowired`一个Mapper接口时，MyBatis并不会给你一个真实的实现类（因为它不存在），而是通过JDK动态代理技术，在内存中动态创建一个实现了该接口的**代理对象**。
> 3.  **调用时拦截执行**：当你调用接口方法（如 `selectById(123)`）时，实际上是调用了这个代理对象的方法。代理对象会拦截这次调用，获取到方法名和参数，然后用`接口全限定名 + 方法名`作为Key，去全局配置中心找到对应的`MappedStatement`，最后交由执行器去完成真正的数据库操作。
> 所以，Mapper接口本身只是一个“契-约”，真正的“实干家”是MyBatis在运行时为你创建的那个看不见的代理对象。

### 广播路由的并发执行机制

你对广播路由的疑问非常到位，这确实是它的关键所在。

-   **Sharding-JDBC内置线程池**：是的，Sharding-JDBC内部维护了一个用于执行SQL的线程池。当它决定进行广播路由时（比如一个`UPDATE`语句不带分片键），它会：
    1.  将一条逻辑SQL改写成32条物理SQL。
    2.  将这32个SQL执行任务提交到它自己的线程池中。
    3.  每个任务都会向底层的HikariCP申请一个真实的数据库连接。
    4.  然后并发地向MySQL服务器发送这32条SQL。

-   **MySQL的并发处理能力**：MySQL服务器本身就是为高并发设计的。当这32个请求几乎同时到达时，MySQL的连接/线程处理器会为这32个（或复用已有的）连接分配不同的服务线程。只要你的MySQL服务器配置的 `max_connections`（最大连接数）足够，并且服务器CPU、I/O资源充足，处理这32个并发查询是完全没有问题的。

-   **为什么广播路由是性能杀手？**
    问题不在于MySQL能否处理并发，而在于**资源放大效应**。
    -   **连接消耗**：你应用中的一次逻辑查询，瞬间占用了32个宝贵的数据库连接。在高并发下，连接池可能瞬间被耗尽。
    -   **数据库压力**：MySQL服务器需要同时启动32个线程来执行查询，CPU和I/O负载瞬间放大32倍。
    -   **网络带宽**：查询结果也要从32张表中分别返回，网络开销同样放大。

**结论**：因此，在业务设计中，**必须极力避免高频的广播路由**。它只适用于低频的管理、运维或数据校对类操作。对于业务查询，如果无法通过分片键路由，就应该采用我们后面讨论的OpenSearch或映射表方案来解决。

---

## 2. 从单表到分表的平滑迁移方案 (Zero-Downtime Migration)

这是一个非常经典的工程问题，面试官想考察的是你对**系统可用性**和**数据一致性**的把控能力。直接切换是绝对不可行的，必须采用平滑、可回滚的方案。以下是一个业界标准的迁移流程：

### 第一阶段：准备工作
1.  **创建新表**：在数据库中创建好32张新的分表（如 `resume_basic_0` 到 `resume_basic_31`）。
2.  **代码改造**：在项目中完成 Sharding-JDBC 的配置，并编写操作新表的 DAO 和 Service/Manager 层代码。此时，这部分代码**不上线**或通过**配置开关**禁用。

### 第二阶段：数据同步
这个阶段的目标是让新老表的数据保持最终一致。

全量数据迁移：在业务低峰期，执行一次性的脚本或使用阿里云DMS等工具，将老表中的存量数据按照分片规则（resume_id % 32）导入到新的32张表中。
增量数据同步（双写）：
修改应用代码，上线一个双写逻辑。对于所有写操作（增、删、改），代码会同时操作老表和新表。
核心原则：以老表写成功为准。即，只要老表写入成功，就向上层返回成功。新表的写入如果失败，需要记录日志，并通过补偿任务（例如定时任务或MQ消息）进行重试，保证数据最终能同步过去。
此时，所有的读操作仍然只访问老表。这个阶段也叫“数据预热”或“影子写入”。

> **面试官追问：全量迁移时，线上数据还在不断写入，如何保证数据的一致性？**
> 这是一个非常棒的追问，直接命中了数据迁移中最棘手的环节。上面提到的“脚本迁移+双写”是一个简化模型，在实际生产环境中，我们会采用更严谨的、基于**变更数据捕获（Change Data Capture, CDC）**的方案来解决这个问题。
> 
> ### 基于CDC的精细化数据同步方案
> 
> 这套方案的核心是利用MySQL的`binlog`事务日志，确保数据在迁移过程中“一丝不差”。
> 
> **前提：** 确保主数据库开启了`binlog`，并且格式是`ROW`模式。
> 
> **第一步：建立一致性快照和同步起点 (Snapshot & Checkpoint)**
> 
> 这是整个迁移过程中**最关键的一步**，它完美地解决了“不知道该从什么位点开始同步”的问题。
> 
> 1.  **开启一个长事务**：在一个维护终端上，连接到旧的数据库，执行 `START TRANSACTION WITH CONSISTENT SNAPSHOT;`。
>     *   这个命令会利用MySQL的MVCC机制，开启一个**可重复读（REPEATABLE READ）**隔离级别的事务。在这个事务里，你看到的所有数据，都像是被“冻结”在了你执行这条命令的那个瞬间。
> 2.  **记录Binlog位点**：立刻执行 `SHOW MASTER STATUS;`。
>     *   这个命令会返回当前数据库正在写入的binlog文件名和位置（Position/GTID）。把这两个值（例如 `mysql-bin.000123` 和 `4567890`）**精确地记录下来**。这个点就是我们后续增量同步的**黄金起点（Checkpoint）**。
> 3.  **导出全量数据**：**在同一个长事务中**，使用 `mysqldump --single-transaction ...` 导出老表的全量数据。因为你是在这个“被冻结”的视图里导出的数据，所以这份全量数据备份，**在逻辑上是和我们刚刚记录的那个Binlog位点完全一致的**。
> 4.  **提交事务**：数据导出完成后，`COMMIT`掉这个长事务。
> 
> **第二步：导入全量数据**
> 
> 将上一步导出的全量数据，通过离线脚本或数据导入工具，写入到新的32张分表中。这个过程可能耗时较长，但没关系，因为我们已经有了增量同步的起点。
> 
> **第三步：启动增量同步 (CDC)**
> 
> 此时轮到CDC工具登场，例如阿里的`Canal`、开源的`Debezium`，或者直接使用云厂商的**数据传输服务（DTS/DMS）**。
> 
> 1.  **配置CDC工具**：配置该工具连接到你的旧数据库。
> 2.  **指定同步起点**：最关键的一步，告诉CDC工具，**从我们在第一步记录的那个黄金Binlog位点开始订阅数据变更**。
> 3.  **启动同步**：CDC工具会从指定的位点开始，读取之后发生的所有`INSERT`, `UPDATE`, `DELETE`操作，并将其推送给一个消费端。
> 4.  **消费并写入新表**：消费端程序接收到变更数据后，解析出`resume_id`，根据分片规则计算出目标表，并将变更应用到对应的新分表中。
> 
> 这个过程会一直持续，直到CDC的同步进度追上实时的数据写入（同步延迟降至毫秒级）。至此，你的新老两套表就实现了**准实时的数据同步**。
> 
> ---
> 
> **小结：** 这个“**一致性快照 + CDC**”的方案，是目前业界进行异构数据库、分库分表等复杂数据迁移任务时最成熟、最可靠的标准实践。它科学地解决了存量和增量数据同步的衔接问题。

### 第三阶段：正式割接 (The Cutover)

这个阶段的目标是：**在极短的窗口期内，将“数据写入的唯一事实来源 (Source of Truth)”从老表安全地切换到新分片表**。这个过程必须精心设计，确保万无一失。

#### 3.1 最终校验与“静默切换”准备

1.  **最终数据校验**：在切换前的最后一刻，再次运行数据稽查脚本，对新老数据进行一次全面的`checksum`或抽样比对。目标是让CDC同步的延迟尽可能低（毫秒级），并且存量数据几乎100%一致。
2.  **上线双写代码**：将包含双写逻辑的应用版本部署上线。这个双写逻辑必须由一个**动态配置开关**控制，**默认是关闭的**。
3.  **停止CDC，开启双写（关键切换点）**：
    这是解决“CDC同步和应用写入相冲突”这一核心问题的关键。它通常在业务低峰期（比如凌晨）进行，操作窗口很短。
    *   **暂停CDC/DTS同步任务**：在配置中心或云厂商控制台，**暂停**从老表到新表的增量数据同步。
    *   **记录最终同步位点**：记下CDC暂停时的最后一个binlog位点，以备回滚。
    *   **立即开启应用层双写**：在暂停CDC的**同一分钟内**，通过配置中心**打开双写开关**。

    **此刻系统状态**：
    *   CDC已经停止，不再有外部数据流写入新表。
    *   应用层开始双写：任何新的写请求，都会**同时写入老表和新分片表**。
    *   所有读请求，**依然只读老表**。
    
    这个“一停一启”的操作，完成了数据同步责任方的交接：从外部的CDC工具，交接给了应用程序本身。整个过程对用户无感知。

#### 3.2 灰度切换读流量（验证新表读取能力）

现在，由于双写的存在，新老两套表的数据在**应用层面是实时强一致的**。这为我们安全地切换读流量创造了完美条件。

1.  **开启读流量灰度**：通过配置中心，开启另一个**读流量控制开关**。
2.  **逐步放量**：
    *   先切 **1%** 的读流量到新分片表。
    *   密切观察新表的**查询性能**（慢SQL、QPS）、应用的**错误率**和**延迟**。
    *   如果一切稳定，逐步加大流量比例：**10% -> 50% -> 100%**。
3.  **设计回滚方案**：这是灰度的意义所在。
    *   **一旦发现新表有问题**（例如性能扛不住、查出的数据有误），可以立刻通过配置开关将读流量**一键切回老表**。
    *   因为双写一直在进行，老表的数据始终是最新的，所以**回滚操作对业务毫无影响**，数据零丢失。

#### 3.3 切换“主写”路径（确立新表为Source of Truth）

当100%的读流量都切换到新表，并且线上服务稳定运行一段时间后（比如24小时），就可以进行最关键的一步：**将“主写”从老表切换到新表**。

1.  **修改双写逻辑**：修改配置或代码逻辑，将双写模式从“**以老表为准**”，切换到“**以新表为准**”。
    *   **切换前**：`try { write_old_db(); } catch { fail; } async_write_new_db();` (以老库成功为准)
    *   **切换后**：`try { write_new_db(); } catch { fail; } async_write_old_db();` (以新库成功为准)
    
    这个切换意味着，从现在开始，**应用的写操作成功与否，只取决于新分片表是否写入成功**。对老表的写入变成了“尽力而为”的异步备份，只是为了保留一条最后的退路。
2.  **观察稳定**：继续让这个“反向”双写模式运行一段时间，确保新表的写入能力完全没有问题。

### 第四阶段：下线老逻辑

当新表作为“唯一事实来源”稳定运行后，迁移就进入了收尾阶段。

1.  **关闭双写**：通过配置中心，彻底关闭双写功能，停止对老表的任何写入操作。此时，应用已经完全运行在新分片表之上了。
2.  **下线老表**：
    *   再次观察一段时间（比如一周），确保没有老表的使用场景被遗漏。
    *   对老表进行最后的备份、归档。
    *   最终，可以安全地从数据库中`DROP`掉老表，彻底完成迁移。

这个方案的优点是平滑、安全、可回滚，每一步都有观测和验证，将迁移风险降到最低。

---

## 3. Sharding Key (`resume_id`) 合理性深度分析

你的思考非常正确。分片键的选择是分库分表设计的灵魂，它直接决定了系统的性能和扩展性。

### `resume_id` 作为分片键的合理性（优点）
1.  **核心业务亲和**：你提到的大部分操作（增删改查）都是通过 `resume_id` 进行的。这使得绝大多数 SQL 请求都能**精确路由到单个分片**，查询效率极高，避免了广播查询，这是最大的优势。
2.  **数据分布均匀**：`resume_id` 通常是趋势递增的，通过取模或哈希，可以保证数据在32张表中均匀分布，不会出现数据倾斜。
3.  **关联查询友好**：项目中使用了 `binding-tables` 策略，将 `resume_basic`, `resume_education` 等一系列表绑定。这意味着一个简历的所有相关信息（基础信息、教育经历等）都会落在同一个库的同一组分片上（例如 `resume_basic_11` 和 `resume_education_11`）。这为将来可能的 `JOIN` 查询（虽然不推荐）或事务操作提供了便利。

### `resume_id` 作为分片键的挑战（缺点）
最大的挑战正如你所说，是**非分片键的查询**，尤其是根据 `user_id` 查询简历列表。这种查询无法定位到具体分片，Sharding-JDBC 会将查询**广播到所有32张表**，然后对结果进行内存归并。当数据量巨大时，这种“**查询风暴**”会严重影响数据库性能。

### 解决方案与权衡

#### 方案一：搜索引擎 (OpenSearch) - **最终一致性方案**
-   **做法**：将简历数据**异步**同步到 OpenSearch 中，建立包含 `user_id` 和 `resume_id` 的索引。
-   **查询流程**：当需要根据 `user_id` 查询时，先请求 OpenSearch 获取该用户下的所有 `resume_id` 列表，再拿着这些 `resume_id` 去请求 Sharding-JDBC。由于 `resume_id` 是分片键，第二次查询效率极高。
-   **优点**：功能强大，不仅能解决 `user_id` 查询问题，还能支持复杂的全文搜索、筛选、排序等需求。将搜索压力与核心数据库隔离。
-   **缺点**：
    -   **数据延迟**：数据从 MySQL 同步到 OpenSearch 存在秒级延迟，不适用于对实时性要求极高的场景。
    -   **维护成本**：需要额外维护一套 OpenSearch 集群。

#### 方案二：用户-简历映射表 - **强一致性方案**
-   **做法**：新建一张 `user_resume_map` 表，字段为 `user_id`, `resume_id`。这张表可以不分片，或者单独以 `user_id` 为分片键。
-   **查询流程**：根据 `user_id` 查询时，先查 `user_resume_map` 表，拿到 `resume_id` 列表，再进行第二次查询。
-   **优点**：
    -   **强一致性**：与主业务库在同一个事务中更新，没有数据延迟。
-   **缺点**：
    -   **额外写开销**：每次创建简历都要多写一次映射表。
    -   **“大用户”问题**：如果某个 `user_id` 拥有海量的简历（比如百万级别），那么这张映射表可能会非常臃肿，单次查询返回大量 `resume_id` 也会有性能问题。

#### 结论与最佳实践
在你的业务场景下，**“`resume_id` 做分片键 + OpenSearch 解决多维查询”是一个非常成熟和经典的架构**。它抓住了主要矛盾（优化核心的高频查询），并用合适的“武器”（搜索引擎）解决了次要矛盾，是权衡成本、性能和复杂度的最佳实践。面试时可以清晰地讲出这个权衡过程。

---

## 4. 水平分表 vs. 垂直分表

你的理解完全正确，这是一个很好的展示你知识体系的机会。

-   **垂直分表 (Vertical Splitting)**：
    -   **定义**：将一个宽表（字段很多）拆分成多个窄表。
    -   **本项目应用**：将一份完整的简历数据，按照业务领域拆分成了 `resume_basic`, `resume_education`, `resume_work` 等多个表。这是典型的垂直分表。
    -   **目的**：使得每个表的结构更清晰，业务更独立，便于维护和扩展。同时，可以提升 I/O 效率，因为查询时可以只加载必要的字段。

-   **水平分表 (Horizontal Splitting / Sharding)**：
    -   **定义**：将一个大表（行数很多）的数据按照某种规则（如 `HASH`, `RANGE`）拆分到多个结构相同的表中。
    -   **本项目应用**：将 `resume_basic` 表拆分成了 `resume_basic_0` 到 `resume_basic_31`。这是典型的水平分表。
    -   **目的**：解决单表数据量过大导致的性能瓶颈，将读写压力分散到多个表中。

在面试时，你可以自信地说：“我们的项目同时采用了垂直分表和水平分表。**先通过垂直分表对业务进行解耦，再对海量数据的核心业务表进行水平分表**，这是一种应对复杂业务和大规模数据的标准组合架构。”

---

## 5. 其他可能遇到的分库分表问题 (Bonus Interview Questions)

1.  **全局唯一ID生成策略**：
    -   **问题**：分表后，不能再依赖 MySQL 的 `auto_increment` 来生成主键了，因为会有冲突。`resume_id` 是如何保证全局唯一的？
    -   **回答**：可以采用**雪花算法 (Snowflake)**。它生成的64位ID包含了时间戳、数据中心ID、机器ID和序列号，既能保证全局唯一，又能趋势递增，非常适合做分片键。也可以使用公司的ID生成器服务，或者基于Redis/Zookeeper实现。

2.  **分布式事务**：
    -   **问题**：如果有一个操作需要同时修改两个不同分片的数据（例如，修改两个不同简历的状态），如何保证事务性？
    -   **回答**：首先，**最佳实践是通过合理设计分片键来避免跨分片事务**。在我们的项目中，由于绝大部分操作都围绕 `resume_id`，所以事务只发生在单个分片内，这是最高效的。如果实在无法避免，Sharding-JDBC 提供了对**分布式事务**的支持，例如基于 XA 协议的强一致性事务和基于 Seata 的最终一致性事务。但它们会带来性能损耗，需要谨慎使用。

3.  **扩容问题（Re-sharding）**：
    -   **问题**：现在是32张表，如果业务继续增长，需要扩容到64张表，该怎么做？
    -   **回答**：这是一个复杂的操作，本质上是一次**数据重分布**。通常的做法类似初次迁移：
        -   新建64张表。
        -   开启**双写**，新数据根据 `resume_id % 64` 的规则写入新表，老数据仍然写入老表。
        -   通过**数据迁移脚本**，将32张老表的数据按照新规则“搬运”到64张新表中。
        -   数据迁移和校验完成后，通过**灰度发布**，逐步将读写流量全部切到新的64张表上。
        -   ShardingSphere 5.x 版本后也提供了弹性伸缩的功能，可以简化这个过程。

4.  **跨分片JOIN查询和复杂聚合**：
    -   **问题**：如果我想统计所有简历中，来自“北京大学”的有多少人，该怎么做？
    -   **回答**：直接在分表上执行 `COUNT(*)` 和 `GROUP BY school` 这样的复杂聚合查询是**非常低效**的，因为它需要扫描所有分片的数据并在内存中计算。这种**OLAP（在线分析处理）**需求不应该由作为 OLTP（在线事务处理）的业务库来承担。正确的做法是：
        -   将数据同步到 **OpenSearch、Elasticsearch** 或**数据仓库（如 ClickHouse, Hive）**中。
        -   在这些专门用于分析和聚合的系统上执行查询。这实现了**业务和分析的隔离**。
