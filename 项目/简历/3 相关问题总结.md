# 简历服务相关问题总结

<details>
<summary><strong>目录</strong></summary>

- [第一部分：线程池饥饿死锁问题分析](#第一部分：线程池饥饿死锁问题分析)
  - [问题背景与现象](#问题背景与现象)
  - [核心代码审查](#核心代码审查)
  - [根本原因分析：线程池饥饿死锁 (Starvation Deadlock)](#根本原因分析：线程池饥饿死锁-starvation-deadlock)
  - [解决方案与最佳实践](#解决方案与最佳实践)
  - [总结](#总结)
- [第二部分：数据库交叉死锁问题分析](#第二部分：数据库交叉死锁问题分析)
  - [死锁日志解读](#死锁日志解读)
  - [核心疑问：为什么看似无关的SQL会死锁？](#核心疑问：为什么看似无关的sql会死锁？)
  - [死锁过程推演 (Classic AB-BA Deadlock)](#死锁过程推演-classic-ab-ba-deadlock)
  - [根源与解决方案](#根源与解决方案)

</details>

## 第一部分：线程池饥饿死锁问题分析

### 一、问题背景与现象

近期，简历服务在线上环境中暴露了一个严重的高并发性能问题。具体表现为：服务在运行一段时间（大约2-3小时）后，处理能力急剧下降，最终导致整个服务崩溃，无法响应任何外部请求，现象类似于“假死”。

监控和日志显示，根本原因是服务内部的核心线程池 `THREAD_POOL_EXECUTOR` 资源被完全耗尽，导致所有依赖该线程池的异步任务都无法执行，最终引发雪崩效应。

### 二、核心代码审查

问题的根源在于两段核心代码的交互方式，它们在异步任务执行中不恰当地**嵌套使用了同一个线程池**。

#### 1. 内部解析逻辑 (`resumeSDKParse`)

在简历解析的下游环节，为了提升效率，系统将简历的不同模块（如基本信息、教育背景、工作经历等）的抽取任务并行化，交由 `CompletableFuture` 执行。

```java
// 内部解析：将一份简历拆分为7个子任务并行处理
public NkResumeTopDTO resumeSDKParse(String fileUrl) {
    JSONObject result = resumeParseService.parseOriginResult(fileUrl);
    NkResumeTopDTO resumeTopDTO = new NkResumeTopDTO();
    // 将不同模块的抽取任务提交到同一个线程池
    CompletableFuture<Void> basicFuture = CompletableFuture.runAsync(() -> resumeTopDTO.setResumeBasicDTO(resumeExtractService.extractNkResumeBasicDTO(result)), THREAD_POOL_EXECUTOR);
    CompletableFuture<Void> eduFuture = CompletableFuture.runAsync(() -> resumeTopDTO.setResumeEducationDTOList(resumeExtractService.extractNkResumeEducationDTO(result)), THREAD_POOL_EXECUTOR);
    CompletableFuture<Void> workFuture = CompletableFuture.runAsync(() -> resumeTopDTO.setResumeWorkDTOList(resumeExtractService.extractNkResumeWorkDTO(result)), THREAD_POOL_EXECUTOR);
    // ... 其他4个模块的Future
    
    List<CompletableFuture<Void>> futures = new ArrayList<>(Arrays.asList(basicFuture, eduFuture, workFuture, ...));
    
    // 等待所有内部任务完成
    CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();
    return resumeTopDTO;
}
```

这段代码本身的设计意图是好的：通过并行处理7个子任务来加速单个简历的解析速度。每个 `resumeSDKParse` 的调用都需要从 `THREAD_POOL_EXECUTOR` 中获取7个线程来执行这些子任务。

#### 2. 外部调用逻辑 (`parseResume` & `parseResumeDefault`)

在上游的调用链路中，系统为了隔离不同的解析策略（如SDK解析、大模型解析等），同样使用了异步化设计，将整个 `resumeSDKParse` 方法作为一个大任务提交。

```java
// 外部调用：将整个SDK解析作为一个大任务提交
public NkResumeTopDTO parseResume(ResumeParseRequest request) {
    // ...
    // 异步获取resumeSDK的解析结果
    CompletableFuture<NkResumeTopDTO> sdkFuture = CompletableFuture.supplyAsync(() -> {
        try {
            // 在这里调用了内部解析方法
            return resumeSDKParse(request.getFileUrl());
        } catch (Exception e) {
            log.error("异步获取SDK解析结果失败", e);
            return null;
        }
    }, THREAD_POOL_EXECUTOR); // 问题关键点：使用了同一个线程池
    
    // ... 其他逻辑 ...
    
    // 等待外部任务完成
    NkResumeTopDTO sdkResult = sdkFuture.join();
    
    // ...
    return result;
}
```

问题的关键点在于，外部的 `supplyAsync` 和内部的 `runAsync` 全部指向了**同一个 `THREAD_POOL_EXECUTOR` 实例**。

### 三、根本原因分析：线程池饥饿死锁 (Starvation Deadlock)

当外部任务和内部任务共享同一个固定大小的线程池时，在高并发场景下会触发经典的“线程池饥饿死锁”问题。

让我们来推演一下死锁的发生过程，假设 `THREAD_POOL_EXECUTOR` 是一个核心线程数为10的线程池：

1.  **外部任务抢占所有线程**：在高并发请求下，10个外部的 `sdkFuture` 任务被创建，并迅速抢占了线程池中全部的10个线程。
2.  **外部任务进入等待**：这10个正在执行的外部任务，其内部逻辑都调用了 `resumeSDKParse` 方法。
3.  **内部任务提交与阻塞**：`resumeSDKParse` 方法会尝试创建7个内部的子任务（`basicFuture`, `eduFuture` 等），并将它们也提交到 `THREAD_POOL_EXECUTOR` 中。
4.  **死锁形成**：
    *   外部任务（占着10个线程）正在执行 `CompletableFuture.allOf(...).join()`，它们**必须等待**其提交的70个内部子任务（`10个外部任务 * 7个内部任务`）全部完成才能释放自己占有的线程。
    *   而这70个内部子任务正在任务队列中排队，它们**必须等待**线程池中有空闲线程才能开始执行。
    *   线程池中的所有线程（10个）都已被外部任务占满，并且这些外部任务因等待内部任务而无法退出。

这就形成了一个完美的闭环死锁：**外部任务等待内部任务的结果，而内部任务等待外部任务释放的线程**。没有任何任务能够向前推进，线程池被完全锁死，无法处理任何新的请求，最终导致服务崩溃。

### 四、解决方案与最佳实践

解决这个问题的核心思想是**隔离资源，打破依赖循环**。

#### 1. 方案一：使用不同的线程池（推荐）

为外部任务和内部任务分别创建和使用不同的线程池。这是一种最清晰、最规范的解决方案。

-   **`OUTER_EXECUTOR`**：用于处理顶层的、编排性质的异步任务。这个线程池的线程数可以相对较少，因为它主要负责任务提交和结果等待。
-   **`INNER_EXECUTOR`**：用于处理底层的、计算密集型的并行子任务。这个线程池的线程数可以设置得大一些，以应对并行的计算需求。

```java
// 示例：定义两个独立的线程池
private static final ExecutorService OUTER_EXECUTOR = Executors.newFixedThreadPool(10, new ThreadFactoryBuilder().setNameFormat("resume-outer-%d").build());
private static final ExecutorService INNER_EXECUTOR = Executors.newFixedThreadPool(20, new ThreadFactoryBuilder().setNameFormat("resume-inner-%d").build());

// 修改后的外部调用
public NkResumeTopDTO parseResume(ResumeParseRequest request) {
    // ...
    CompletableFuture<NkResumeTopDTO> sdkFuture = CompletableFuture.supplyAsync(() -> {
        return resumeSDKParse(request.getFileUrl());
    }, OUTER_EXECUTOR); // 使用外部线程池
    // ...
}

// 修改后的内部解析
public NkResumeTopDTO resumeSDKParse(String fileUrl) {
    // ...
    CompletableFuture<Void> basicFuture = CompletableFuture.runAsync(..., INNER_EXECUTOR); // 使用内部线程池
    CompletableFuture<Void> eduFuture = CompletableFuture.runAsync(..., INNER_EXECUTOR); // 使用内部线程池
    // ...
}
```

**优点**：物理上隔离了资源，外部任务的阻塞不会影响内部任务的执行，彻底解决了死锁问题。代码结构清晰，职责分明。

#### 2. 方案二：避免不必要的 `join()` 和异步嵌套

重新审视代码，如果外部的 `supplyAsync` 并不是必须的（例如，如果上游调用者可以接受同步等待），可以考虑简化设计。

```java
// 简化后的外部调用
public NkResumeTopDTO parseResume(ResumeParseRequest request) {
    // ...
    // 直接同步调用，让 resumeSDKParse 内部的并行发挥作用
    NkResumeTopDTO sdkResult = resumeSDKParse(request.getFileUrl());
    
    // 如果上层确实需要异步，那么应该在更上层完成，而不是在这里嵌套
    
    // ...
}
```

**优点**：简化了代码逻辑，减少了一层异步嵌套。
**缺点**：可能会将同步阻塞的压力转移到上游调用者，需要整体评估。

### 五、总结

线程池嵌套使用同一个实例是高并发编程中一个非常隐蔽的陷阱。它在低并发时可能不会暴露问题，但一旦流量上升，就会导致灾难性的“饥饿死锁”。

**核心原则**：
1.  **隔离原则**：执行不同性质任务（IO密集型 vs CPU密集型，长任务 vs 短任务，编排任务 vs 执行任务）的线程池应该进行物理隔离。
2.  **避免阻塞**：尽量避免在线程池任务中进行长时间的阻塞等待（如 `join()`, `get()`）。如果必须等待，请确保等待的任务不会因资源竞争而无法开始。
3.  **审慎嵌套**：对于任何形式的异步嵌套调用，都要仔细审查其资源依赖关系，特别是线程池的共享情况，确保不会产生循环等待。

---

## 第二部分：数据库交叉死锁问题分析

在服务日常运维中，除了线程池问题，数据库死锁也是一个常见且棘手的高并发问题。以下是一个线上真实发生的死锁案例及其分析。

### 1. 死锁日志解读

我们从数据库的 `SHOW ENGINE INNODB STATUS` 日志中捕获到了以下死锁信息：

**事务 1 (等待方)**
-   **持有锁 (Holding Lock)**: 在 `resume_education_23` 表的主键索引上持有一个 `X` 锁 (排他锁)。
-   **等待锁 (Waiting for Lock)**: 试图在 `resume_campus_23` 表的主键索引上获取一个 `X` 锁，但被阻塞。
-   **执行的SQL**: `UPDATE resume_campus_23 SET status=1 WHERE resume_id = 26204631`

**事务 2 (被回滚方)**
-   **持有锁 (Holding Lock)**: 在 `resume_campus_23` 表的主键索引上持有一个 `X` 锁。
-   **等待锁 (Waiting for Lock)**: 试图在 `resume_education_23` 表的主键索引上获取一个 `X` 锁，但被阻塞。
-   **执行的SQL**: `UPDATE resume_education_23 SET ... WHERE resume_id=26204631 AND id=607135`

### 2. 核心疑问：为什么看似无关的SQL会死锁？

初看之下，一个在更新 `resume_campus_23`，另一个在更新 `resume_education_23`，似乎是两个不同的操作。但这里的核心误区在于，**我们必须从一个完整的业务事务（Transaction）视角来看，而不是单个SQL语句。**

这两个事务都**同时操作了 `resume_education_23` 和 `resume_campus_23` 这两张表**，只是它们获取锁的**顺序正好相反**。

### 3. 死锁过程推演 (Classic AB-BA Deadlock)

这是一个非常典型的“交叉锁定”导致的死锁，我们可以清晰地推演出其发生过程：

1.  **时刻 T1**: `事务1` 开始执行，它先更新了 `resume_education_23`，成功获取了该表相关记录的 `X` 锁。
2.  **时刻 T2**: `事务2` 开始执行，它先更新了 `resume_campus_23`，也成功获取了该表相关记录的 `X` 锁。
3.  **时刻 T3**: `事务1` 继续执行，试图更新 `resume_campus_23`。它请求获取该表的 `X` 锁，但发现这个锁已经被 `事务2` 在 T2 时刻持有，于是 `事务1` 进入**等待**状态。
4.  **时刻 T4**: `事务2` 继续执行，试图更新 `resume_education_23`。它请求获取该表的 `X` S锁，但发现这个锁已经被 `事务1` 在 T1 时刻持有，于是 `事务2` 也进入**等待**状态。

此时，死锁形成：
-   `事务1` 拥有 `education` 表的锁，等待 `campus` 表的锁。
-   `事务2` 拥有 `campus` 表的锁，等待 `education` 表的锁。

两者互相等待对方释放资源，形成了一个无法解开的循环等待，最终InnoDB的死锁检测机制发现此情况，选择回滚其中一个事务（通常是undo量较小的那个）来打破僵局。

### 4. 根源与解决方案

-   **根本原因**：应用代码中存在**多个业务逻辑**，它们都需要更新同一组资源（`resume_education_23` 和 `resume_campus_23` 这两张表），但是它们获取这些资源的**加锁顺序不一致**。

-   **解决方案**：
    1.  **统一加锁顺序 (推荐)**：这是解决这类死锁问题的最根本方法。梳理所有需要同时操作这两张表的业务代码，并强制规定一个统一的加锁顺序。例如，**永远先更新 `resume_campus_23`，再更新 `resume_education_23`**。这样，所有事务都会沿着同一个方向请求锁，就不会形成环路。
    2.  **缩短事务范围**：检查业务逻辑，看是否能将一个大的事务拆分成几个更小的、独立的事务，减少锁的持有时间。但这需要仔细评估数据一致性要求。
    3.  **使用乐观锁**：对于并发冲突不那么激烈的场景，可以考虑使用带 `version` 字段的乐观锁来代替悲观锁，通过重试来解决冲突，而不是让数据库死锁。

**结论**：数据库死锁问题，特别是这种交叉锁定，其根源几乎总是在于应用层代码对资源加锁的顺序不一致。解决的关键在于建立和遵守统一的资源访问顺序。
